{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO2xV3YWUKmsDusq3f8Azm8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dead10GOD/ollama_test/blob/main/flask_Tested01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nIs4OsE9HDZH",
        "outputId": "16f32582-555d-4e13-c003-133fd82ef431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightrag[ollama] in /usr/local/lib/python3.10/dist-packages (0.1.0b6)\n",
            "Requirement already satisfied: backoff<3.0.0,>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (2.2.1)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (3.1.4)\n",
            "Requirement already satisfied: jsonlines<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (4.0.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (1.6.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.4 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (1.26.4)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (1.0.1)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (6.0.2)\n",
            "Requirement already satisfied: tiktoken<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.4 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (4.66.6)\n",
            "Requirement already satisfied: ollama<0.3.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (0.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.3->lightrag[ollama]) (3.0.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines<5.0.0,>=4.0.0->lightrag[ollama]) (24.2.0)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from ollama<0.3.0,>=0.2.1->lightrag[ollama]) (0.27.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.8.0,>=0.7.0->lightrag[ollama]) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.8.0,>=0.7.0->lightrag[ollama]) (2.32.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->lightrag[ollama]) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->lightrag[ollama]) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (1.2.2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Answer:** Let's dive into the fascinating case of **Ramana Dayaram Shetty vs The International Airport Authority of India** decided on May 4, 1979.\n\n**Part 1: Background and Facts**\n\nThe case involves Ramana Dayaram Shetty, an Indian citizen who lost his luggage at the Bombay (now Mumbai) airport. He claimed compensation for the loss from the International Airport Authority of India (IAAI), which manages several major airports in India, including Bombay's Santacruz Airport.\n\nShetty's luggage was mishandled by the IAAI staff, and he received a paltry sum as compensation after filing a claim. Feeling dissatisfied with the amount awarded to him, Shetty decided to take his case to court, arguing that the IAAI was responsible for the loss of his luggage due to their negligence.\n\n**Question 1:**\nDo you think it's reasonable for airlines or airport authorities to be held liable for mishandled luggage? Should passengers have more recourse in such cases?\n\nLet's move on to **Part 2: Proceedings and Arguments**\n\nShetty approached the Bombay High Court with his claim, which was subsequently transferred to the Supreme Court of India. The IAAI argued that they were not responsible for the loss of Shetty's luggage since it occurred while the bag was in the custody of the airlines.\n\n**Question 2:**\nWho do you think should bear the responsibility in this case: the airport authority, the airline, or perhaps both? Should there be joint liability?\n\nMoving on to **Part 3: Judgement and Verdict**\n\nThe Supreme Court of India ruled that the IAAI was indeed liable for the loss of Shetty's luggage. The court held that since the bag was in the custody of the airport authority when it went missing, they were responsible for its safekeeping.\n\n**Question 3:**\nDo you think this verdict sets a precedent for other cases involving mishandled luggage? Should airports and airlines work together to improve baggage handling processes?\n\nLet's move on to **Part 4: Implications and Consequences**\n\nThis judgment has significant implications for the aviation industry in India. The IAAI will now have to compensate Shetty for his losses, setting a precedent for similar cases.\n\n**Question 4:**\nWhat do you think could be the long-term effects of this verdict on airport operations and passenger confidence?\n\nLet's conclude with a **Summary of the Case**\n\nThe case of Ramana Dayaram Shetty vs The International Airport Authority of India was decided in favor of the plaintiff, holding the IAAI responsible for the loss of his luggage. This ruling has far-reaching implications for the aviation industry in India and highlights the importance of accountability and compensation for passengers.\n\n**Key Points:**\n\n* The IAAI is liable for the safekeeping of luggage at airports.\n* Passengers have recourse against airport authorities in cases of mishandled luggage.\n* Joint liability between airlines and airport authorities may be considered in similar cases.\n\n**Actual Verdict:** The Supreme Court of India ruled that the IAAI was responsible for compensating Shetty for his losses."
          },
          "metadata": {}
        }
      ],
      "source": [
        "!sudo apt-get install -y pciutils\n",
        "!curl -fsSL https://ollama.com/install.sh | sh # download ollama api\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Create a Python script to start the Ollama API server in a separate thread\n",
        "\n",
        "import os\n",
        "import threading\n",
        "import subprocess\n",
        "import requests\n",
        "import json\n",
        "\n",
        "def ollama():\n",
        "    os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
        "    os.environ['OLLAMA_ORIGINS'] = '*'\n",
        "    subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "ollama_thread = threading.Thread(target=ollama)\n",
        "ollama_thread.start()\n",
        "\n",
        "from IPython.display import clear_output\n",
        "!ollama pull llama3.1:8b\n",
        "clear_output()\n",
        "\n",
        "!pip install -U lightrag[ollama]\n",
        "\n",
        "from lightrag.core.generator import Generator\n",
        "from lightrag.core.component import Component\n",
        "from lightrag.core.model_client import ModelClient\n",
        "from lightrag.components.model_client import OllamaClient, GroqAPIClient\n",
        "\n",
        "import time\n",
        "\n",
        "\n",
        "qa_template = r\"\"\"<SYS>\n",
        "You are a helpful assistant.\n",
        "</SYS>\n",
        "User: {{input_str}}\n",
        "You:\"\"\"\n",
        "\n",
        "class SimpleQA(Component):\n",
        "    def __init__(self, model_client: ModelClient, model_kwargs: dict):\n",
        "        super().__init__()\n",
        "        self.generator = Generator(\n",
        "            model_client=model_client,\n",
        "            model_kwargs=model_kwargs,\n",
        "            template=qa_template,\n",
        "        )\n",
        "\n",
        "    def call(self, input: dict) -> str:\n",
        "        return self.generator.call({\"input_str\": str(input)})\n",
        "\n",
        "    async def acall(self, input: dict) -> str:\n",
        "        return await self.generator.acall({\"input_str\": str(input)})\n",
        "\n",
        "from lightrag.components.model_client import OllamaClient\n",
        "from IPython.display import Markdown, display\n",
        "model = {\n",
        "    \"model_client\": OllamaClient(),\n",
        "    \"model_kwargs\": {\"model\": \"llama3.1:8b\"}\n",
        "}\n",
        "qa = SimpleQA(**model)\n",
        "output=qa(\"\"\"Consider the case **Ramana Dayaram Shetty vs The International Airport Authority of India** decided on May 4, 1979. Your task is to reconstruct the case proceedings in a detailed, step-by-step narrative format.\n",
        "For each significant part of the case:\")\n",
        "1. Present the case proceedings in a clear and engaging way.\n",
        "2. Ask an analytical or opinion-based question related to the preceding part. These questions should be concise and fall into one of the following categories:\n",
        "   - Agree/Disagree type\n",
        "   - Analytical opinion type (e.g., \"Who do you think is right? or Do you think this was moral according to this or that law\")\n",
        "   - Predictive questions (e.g., \"What do you think could happen next this or that ? \")\n",
        "3. Keep it interactive like the user feels immersed in the case\n",
        "4. Do not wait for user answers; proceed directly to the next part of the case after each question.\n",
        "5. Conclude the output with a summary of the case, its key points, and the actual verdict delivered by the court.\n",
        "\n",
        "Ensure a conversational tone that engages the user and guides them through the case while prompting thought and reflection on the legal, ethical, and practical dimensions of the case.\"\"\")\n",
        "display(Markdown(f\"**Answer:** {output.data}\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask flask-cors\n",
        "!pip install flask flask-cors pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2mikhE8TAQF",
        "outputId": "6a3619b9-cdb4-4db8-ba3b-1440b5faee16"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Collecting flask-cors\n",
            "  Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl (14 kB)\n",
            "Installing collected packages: flask-cors\n",
            "Successfully installed flask-cors-5.0.0\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.10/dist-packages (5.0.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Downloading pyngrok-7.2.1-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "from pyngrok import ngrok\n",
        "\n"
      ],
      "metadata": {
        "id": "e62_xvvJTBCu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n",
        "from pyngrok import ngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cydq74k7Tvi5",
        "outputId": "0d72795f-c932-434d-d96e-9f43cd8f07d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__)\n",
        "CORS(app)  # Enable Cross-Origin Resource Sharing\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc8d-DV9Tzbe",
        "outputId": "92775f7a-0373-45e0-8dea-8bd8b5d7c8ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<flask_cors.extension.CORS at 0x7b232952a860>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@app.route('/generate', methods=['POST'])\n",
        "def generate_response():\n",
        "    # Get the user input from the POST request\n",
        "    data = request.json\n",
        "    user_input = data.get('input', '')\n",
        "\n",
        "    # Simulated response from the Ollama model\n",
        "    # Replace this with the call to your model or logic if needed\n",
        "    model_output = f\"Ollama's response to: {user_input}\"\n",
        "\n",
        "    # Return the response as JSON\n",
        "    return jsonify({'output': model_output})\n",
        "\n"
      ],
      "metadata": {
        "id": "Qcq-pilwT69M"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Flask server\n",
        "from threading import Thread\n",
        "\n",
        "def run_flask():\n",
        "    app.run(host='0.0.0.0', port=5000)\n",
        "\n",
        "thread = Thread(target=run_flask)\n",
        "thread.start()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27VPcsP8U_km",
        "outputId": "a240fc82-9317-47be-d6f0-9b494206dec0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2peT5bHowRgMVRmJjg1uAva52KO_38Syaei4L82pR46rs3YYj\n"
      ],
      "metadata": {
        "id": "sF3AQc80VBwd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "626a99a6-57a8-42df-a1af-8b3d2271abef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "public_url = ngrok.connect(5000)\n",
        "print(f\"Public URL: {public_url}\")\n"
      ],
      "metadata": {
        "id": "zwHhkp2vt6Od",
        "outputId": "e323e25e-cd38-4119-c13d-cfc8a8632fdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://ab45-34-16-198-204.ngrok-free.app\" -> \"http://localhost:5000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -X POST -H \"Content-Type: application/json\" \\\n",
        "-d '{\"input\": \"Test input\"}' \\\n",
        "http://1234-56-789.ngrok.io/generate\n"
      ],
      "metadata": {
        "id": "CN6SGNtXj5L6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WQ19u-TEt2G9"
      }
    }
  ]
}