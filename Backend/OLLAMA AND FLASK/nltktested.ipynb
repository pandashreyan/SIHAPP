{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNfJbj+nzdihiqcerFeNY2c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dead10GOD/ollama_test/blob/main/nltktested.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3T0DkM08jTH",
        "outputId": "43575b1c-b2ef-48f2-edea-411d6e74f620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Legal Case Analysis Result:\n",
            "--------------------------------------------------\n",
            "Main Problem: Complex Legal Scenario: Name and territory of the Union\n",
            "(1) India, that is Bharat, shall be a Union of States\n",
            "(2) The States and the territories thereof shall be as specified in the First Schedule\n",
            "(3) The territory of India shall comprise\n",
            "The territories of the States; the Union territories specified in the First Schedule; and such other territories as may be acquired\n",
            "\n",
            "Subproblems:\n",
            "- Subproblem 1: Analyze the legal implications of 'Name and territory of the Union\n",
            "(1) India, that is Bharat, shall be a Union of States\n",
            "(2) The States and the territories thereof shall be as specified in the First Schedule\n",
            "(3) The territory of India shall comprise\n",
            "The territories of the States; the Union territories specified in the First Schedule; and such other territories as may be acquired'.\n",
            "\n",
            "User Responses: ['agree', 'partially agree', 'disagree']\n",
            "\n",
            "--- Original Verdict ---\n",
            "This article ensures administrative continuity, defining the transition of high-ranking officials under constitutional provisions.\n",
            "\n",
            "--- Comprehensive Verdict ---\n",
            "The analysis reveals a balanced perspective. The original verdict 'This article ensures administrative continuity, defining the transition of high-ranking officials under constitutional provisions.' requires further scrutiny.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "class AdvancedLegalAnalysisCrew:\n",
        "    def __init__(self, csv_path='final database.csv'):\n",
        "        \"\"\"\n",
        "        Initialize the legal analysis crew with a CSV path\n",
        "\n",
        "        Args:\n",
        "            csv_path (str): Path to the CSV file containing legal cases\n",
        "        \"\"\"\n",
        "        # Initialize path and vectorizer\n",
        "        self.csv_path = csv_path\n",
        "        self.vectorizer = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "    def semantic_similarity(self, doc1, doc2):\n",
        "        \"\"\"\n",
        "        Calculate semantic similarity between two documents\n",
        "\n",
        "        Args:\n",
        "            doc1 (str): First document\n",
        "            doc2 (str): Second document\n",
        "\n",
        "        Returns:\n",
        "            float: Cosine similarity between documents\n",
        "        \"\"\"\n",
        "        vectors = self.vectorizer.fit_transform([doc1, doc2])\n",
        "        return cosine_similarity(vectors)[0][1]\n",
        "\n",
        "    def process_legal_case(self):\n",
        "        \"\"\"\n",
        "        Process the first legal case from the CSV\n",
        "\n",
        "        Returns:\n",
        "            dict: Comprehensive analysis of the legal case\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Read CSV and process the first case\n",
        "            df = pd.read_csv(self.csv_path)\n",
        "\n",
        "            # Check if required columns exist\n",
        "            required_columns = ['article_desc', 'verdict']\n",
        "            for col in required_columns:\n",
        "                if col not in df.columns:\n",
        "                    raise ValueError(f\"Missing required column: {col}\")\n",
        "\n",
        "            first_case = df.iloc[0]\n",
        "\n",
        "            # Extract details from CSV\n",
        "            article_desc = first_case['article_desc']\n",
        "            original_verdict = first_case['verdict']\n",
        "\n",
        "            # Generate narrative and subproblems\n",
        "            main_problem = self._generate_narrative(article_desc)\n",
        "            subproblems = self._generate_advanced_subproblems(article_desc)\n",
        "\n",
        "            # Simulate responses\n",
        "            user_responses = self._evaluate_subproblem_responses(subproblems)\n",
        "\n",
        "            # Generate comprehensive verdict\n",
        "            comprehensive_verdict = self._generate_comprehensive_verdict(\n",
        "                main_problem, subproblems, user_responses, original_verdict\n",
        "            )\n",
        "\n",
        "            # Return the complete case analysis\n",
        "            return {\n",
        "                \"main_problem\": main_problem,\n",
        "                \"subproblems\": subproblems,\n",
        "                \"user_responses\": user_responses,\n",
        "                \"original_verdict\": original_verdict,\n",
        "                \"comprehensive_verdict\": comprehensive_verdict\n",
        "            }\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: File not found at {self.csv_path}\")\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "            return None\n",
        "\n",
        "    def _generate_narrative(self, article_desc):\n",
        "        \"\"\"\n",
        "        Create a narrative from article description\n",
        "\n",
        "        Args:\n",
        "            article_desc (str): Description of the article\n",
        "\n",
        "        Returns:\n",
        "            str: Generated narrative\n",
        "        \"\"\"\n",
        "        sentences = sent_tokenize(article_desc)\n",
        "        narrative = f\"Complex Legal Scenario: {' '.join(sentences)}\"\n",
        "        return narrative\n",
        "\n",
        "    def _generate_advanced_subproblems(self, article_desc):\n",
        "        \"\"\"\n",
        "        Generate advanced subproblems based on article description\n",
        "\n",
        "        Args:\n",
        "            article_desc (str): Description of the article\n",
        "\n",
        "        Returns:\n",
        "            list: List of generated subproblems\n",
        "        \"\"\"\n",
        "        sentences = sent_tokenize(article_desc)\n",
        "        subproblems = [\n",
        "            f\"Subproblem {i+1}: Analyze the legal implications of '{sentence}'.\"\n",
        "            for i, sentence in enumerate(sentences[:min(3, len(sentences))])\n",
        "        ]\n",
        "        return subproblems\n",
        "\n",
        "    def _evaluate_subproblem_responses(self, subproblems):\n",
        "        \"\"\"\n",
        "        Simulate intelligent evaluation of subproblem responses\n",
        "\n",
        "        Args:\n",
        "            subproblems (list): List of generated subproblems\n",
        "\n",
        "        Returns:\n",
        "            list: Simulated response for each subproblem\n",
        "        \"\"\"\n",
        "        # Replace with more sophisticated logic if needed\n",
        "        return [\"agree\", \"partially agree\", \"disagree\"]\n",
        "\n",
        "    def _generate_comprehensive_verdict(self, main_problem, subproblems, user_responses, original_verdict):\n",
        "        \"\"\"\n",
        "        Generate a comprehensive verdict\n",
        "\n",
        "        Args:\n",
        "            main_problem (str): Main problem description\n",
        "            subproblems (list): List of subproblems\n",
        "            user_responses (list): Responses to subproblems\n",
        "            original_verdict (str): Original verdict from the database\n",
        "\n",
        "        Returns:\n",
        "            str: Comprehensive legal verdict\n",
        "        \"\"\"\n",
        "        # Basic logic to generate a verdict based on subproblem responses\n",
        "        agreement_count = user_responses.count(\"agree\")\n",
        "        disagreement_count = user_responses.count(\"disagree\")\n",
        "\n",
        "        if agreement_count > disagreement_count:\n",
        "            verdict = f\"Based on the analysis of {len(subproblems)} subproblems, the court finds substantial merit in the original verdict: {original_verdict}\"\n",
        "        elif disagreement_count > agreement_count:\n",
        "            verdict = f\"After careful review of {len(subproblems)} subproblems, the court recommends a re-examination of the original verdict: {original_verdict}\"\n",
        "        else:\n",
        "            verdict = f\"The analysis reveals a balanced perspective. The original verdict '{original_verdict}' requires further scrutiny.\"\n",
        "\n",
        "        return verdict\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to demonstrate the usage of AdvancedLegalAnalysisCrew\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Path to your CSV file\n",
        "        csv_path = 'final database.csv'\n",
        "\n",
        "        # Initialize the legal analysis crew\n",
        "        legal_crew = AdvancedLegalAnalysisCrew(csv_path=csv_path)\n",
        "\n",
        "        # Process the first case\n",
        "        result = legal_crew.process_legal_case()\n",
        "\n",
        "        if result:\n",
        "            # Print the entire result, with emphasis on the verdict\n",
        "            print(\"Legal Case Analysis Result:\")\n",
        "            print(\"-\" * 50)\n",
        "            print(f\"Main Problem: {result['main_problem']}\")\n",
        "            print(\"\\nSubproblems:\")\n",
        "            for subproblem in result['subproblems']:\n",
        "                print(f\"- {subproblem}\")\n",
        "            print(\"\\nUser Responses:\", result['user_responses'])\n",
        "            print(\"\\n--- Original Verdict ---\")\n",
        "            print(result['original_verdict'])\n",
        "            print(\"\\n--- Comprehensive Verdict ---\")\n",
        "            print(result['comprehensive_verdict'])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred in main: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}